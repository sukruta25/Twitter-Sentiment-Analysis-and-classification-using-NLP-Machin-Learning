{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ed462a-8b58-4abc-bbdc-98ab63d9911e",
   "metadata": {},
   "source": [
    "1. starting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cde01ec-2195-450c-bfc5-0b10d097d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/timesofindia')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "# # Your scraping code here\n",
    "\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c1781d2-d055-42aa-af56-2069e9026ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "\n",
    "# Extract tweets\n",
    "tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "tweets_list = [tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38b2df9d-0dd7-40fb-93a4-76b716229d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A massive fire broke out at a car workshop in #Gurgaon’s Silokhra village, destroying 15 high-end vehicles worth Rs 10 crore\\n\\nKnow morehttp://toi.in/LxhKha',\n",
       " '#Watch | Visuals from #Kerala as search, rescue and relief operations still continue in the landslide-affected #Wayanad',\n",
       " 'Deputy Chief Minister #DevendraFadnavis alleged that the #MahaVikasAghadi (MVA) government had plotted to imprison him and other #BJP leaders by coercing police officers\\n\\nRead morehttp://toi.in/0VOGvb \\n\\n#Nagpur']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50645e9c-6ea3-428b-8d53-31d3ef8915d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3a5f917-1c1b-486d-8ec0-ef85356ac31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A massive fire broke out at a car workshop in #Gurgaon’s Silokhra village, destroying 15 high-end vehicles worth Rs 10 crore\n",
      "\n",
      "Know morehttp://toi.in/LxhKha\n",
      "#Watch | Visuals from #Kerala as search, rescue and relief operations still continue in the landslide-affected #Wayanad\n",
      "Deputy Chief Minister #DevendraFadnavis alleged that the #MahaVikasAghadi (MVA) government had plotted to imprison him and other #BJP leaders by coercing police officers\n",
      "\n",
      "Read morehttp://toi.in/0VOGvb \n",
      "\n",
      "#Nagpur\n"
     ]
    }
   ],
   "source": [
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6bd113-a06e-4697-bd27-6db69ea24e77",
   "metadata": {},
   "source": [
    "2. extract 50 tweets from times of india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db714d74-4eaa-40c2-8a19-262c26b5cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)  # Wait for new tweets to load\n",
    "\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text not in tweets_list:  # Avoid duplicates\n",
    "                tweets_list.append(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7e64741-9c3b-426a-8afc-f1c8b0e8a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets(driver, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6edd31b-7116-491f-b094-7f1d0a6b6801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Paris2024  #Olympics  #OlympicGames \n",
      "\n",
      "#Boxing  fights for \n",
      "@Olympics\n",
      "  future after gender-row 'disaster' \n",
      "\n",
      "Full Story  http://toi.in/ai0NBY98\n",
      "Coffee shop employee arrested in #Bengaluru for attempting to film women using washroom\n",
      "\n",
      "A 23-year-old man working in one of the well-known coffee chains was caught trying to film women using the washroom\n",
      "\n",
      "Know morehttp://toi.in/Rpxe2Z\n",
      "#Watch | Visuals from #HimachalPradesh's #Dharamshala as rivers are in spate as city witnesses heavy rainfall\n"
     ]
    }
   ],
   "source": [
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb41dc-dd9c-4913-b057-9269f303a0a0",
   "metadata": {},
   "source": [
    "3. another try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58f61de3-6e10-41bf-8fe1-7c44a0df2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def extract_tweets(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list:  # Avoid duplicates\n",
    "                tweets_list.append(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8f934a8-3682-407d-91b4-f4fafa6c930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A massive fire broke out at a car workshop in #Gurgaon’s Silokhra village, destroying 15 high-end vehicles worth Rs 10 crore\n",
      "\n",
      "Know morehttp://toi.in/LxhKha\n",
      "#Watch | Visuals from #Kerala as search, rescue and relief operations still continue in the landslide-affected #Wayanad\n",
      "Deputy Chief Minister #DevendraFadnavis alleged that the #MahaVikasAghadi (MVA) government had plotted to imprison him and other #BJP leaders by coercing police officers\n",
      "\n",
      "Read morehttp://toi.in/0VOGvb \n",
      "\n",
      "#Nagpur\n"
     ]
    }
   ],
   "source": [
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets(driver, 5000)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "676893c7-94c6-49a6-9877-beef72e4a59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c74caa-20f0-4e1e-b6ca-a01e93cbff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'timesofindia_tweets.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2c83e-f2d2-406c-941d-964d0f0e2682",
   "metadata": {},
   "source": [
    "4. through load balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7bf4f042-31fd-42b1-a383-dfa5c8381820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Watch | Visuals from #WestBengal as Junior doctors at #Kolkata's RG Kar Medical College and Hospital protest over the sexual assault and murder of a woman post-graduate trainee (PGT) doctor at the hospital\n",
      "'Please do not message or call me': Phone, WhatsApp hacked, claims #NCP (SP) MP #SupriyaSule \n",
      "\n",
      "Know morehttp://toi.in/_mHB6a62 \n",
      "\n",
      "#Delhi\n",
      "#Watch | Visuals from #Haryana as a special khap panchayat meeting called in Charkhi #Dadri for wrestler #VineshPhogat, demanding justice for her.  \n",
      "\n",
      "#Olympics#Paris2024 #Paris2024Olympics\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/timesofindia')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list:  # Avoid duplicates\n",
    "                tweets_list.append(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list\n",
    "\n",
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets(driver, 50)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83c74615-69e8-4698-9247-734a8ed8dfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e220187e-5d58-4264-a5a4-befe94c8d739",
   "metadata": {},
   "source": [
    "thread pool for paralle processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69702d47-02f2-4500-8c11-e374d7a2110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Former Bangladeshi Prime Minister #SheikhHasina accused the #UnitedStates of influencing her resignation to gain control over Saint Martin Island and the Bay of Bengal\n",
      "\n",
      "Details herehttp://toi.in/pzhTXY\n",
      "\n",
      "#Bangladesh #BangladeshCrisis\n",
      "#Watch | Visuals from #WestBengal as Junior doctors at #Kolkata's RG Kar Medical College and Hospital protest over the sexual assault and murder of a woman post-graduate trainee (PGT) doctor at the hospital\n",
      "'Please do not message or call me': Phone, WhatsApp hacked, claims #NCP (SP) MP #SupriyaSule \n",
      "\n",
      "Know morehttp://toi.in/_mHB6a62 \n",
      "\n",
      "#Delhi\n",
      "From #health tips to #wellness mantras, TOI Health+ is here to help you switch to a healthier lifestyle. Know more: http://toi.in/HealthPlus \n",
      "@TOIHealth_Plus\n",
      "#Watch | Visuals from #Haryana as rainfall in #Gurugram causes waterlogging in several parts of the city\n",
      "#Kolkata doctor death: Who is Sanjay Roy? civic volunteer arrested in RG Kar Hospital rape-murder case\n",
      "\n",
      "The arrest came just six hours after a seven-member Special Investigation Team was formed to investigate the case\n",
      "\n",
      "Read morehttp://toi.in/Z0Gpub\n",
      "\n",
      "#Kolkata #WestBengal\n",
      "Big meeting of Aam Aadmi Party today at 6 pm over Delhi Assembly elections. It will be held at Manish Sisodia's residence.\n",
      "#Paris2024 #Hockey \n",
      "\n",
      "Paris Olympics: Indian men's hockey team receives heroic welcome at Amritsar airport\n",
      "#NeerajChopra showed his silver medal to the crowd and apologized for not bringing home the gold. He highlighted the hard work\n",
      "\n",
      "Know morehttp://toi.in/CzmKTZ \n",
      "\n",
      "#Paris2024 #OlympicGamesParis2024 #Olympic2024\n",
      "Taiwan gender-row boxer Lin Yu-ting seals emphatic Paris Olympics gold\n",
      "\n",
      "READ: http://toi.in/MdoZKZ/a24gk\n",
      "\n",
      "#LinYuTing #Paris2024 #Olympics\n",
      "Former Bangladeshi Prime Minister #SheikhHasina accused the #UnitedStates of influencing her resignation to gain control over Saint Martin Island and the Bay of Bengal\n",
      "\n",
      "Details herehttp://toi.in/pzhTXY\n",
      "\n",
      "#Bangladesh #BangladeshCrisis\n",
      "#Watch | Visuals from #WestBengal as Junior doctors at #Kolkata's RG Kar Medical College and Hospital protest over the sexual assault and murder of a woman post-graduate trainee (PGT) doctor at the hospital\n",
      "'Please do not message or call me': Phone, WhatsApp hacked, claims #NCP (SP) MP #SupriyaSule \n",
      "\n",
      "Know morehttp://toi.in/_mHB6a62 \n",
      "\n",
      "#Delhi\n",
      "Gender row Olympic boxing champion Imane Khelif files complaint for online harassment: Lawyer\n",
      "\n",
      "READ: http://toi.in/EoMCJZ/a24gk\n",
      "\n",
      "#ImaneKhelif #Paris2024 #OlympicGames\n",
      "#WATCH | Visuals from #Amritsar, #Punjab as Captain of the Indian men's #Hockey team #HarmanpreetSingh says, \"I am feeling very happy...We offered prayers at Sri Harmandir Sahib (Golden Temple)...\" \n",
      "\n",
      "#ParisOlympics2024 #Paris2024 #Olympics2024Paris\n",
      "Thousands hit streets in protest against attacks post-#Hasina exit in #Bangladesh\n",
      "#MadhabiPuriBuch, #SEBI chairperson, and her husband, #DhavalBuch, denied allegations by #HindenburgResearch regarding their involvement in offshore entities tied to the #AdaniGroup scandal\n",
      "\n",
      "Know morehttp://toi.in/PTlK8Z\n",
      "#Watch | Visuals from #Haryana's #Gurugram as severe waterlogging witnessed after incessant rainfall in the area; visuals from Gurugram Sector 5\n",
      "Father of the second-year post graduate trainee (PGT) doctor - whose brutalised body was found in a seminar hall of RG Kar Medical College and Hospital on Saturday said his family had complete faith in Chief Minister #MamataBanerjee and the police probe into her daughter's\n",
      "#WATCH | Anantnag, J&K: Operation underway by Indian Army to track down terrorists at Ahlan Gadool in Kokernag area. Two Army soldiers lost their lives in action and two civilians were injured in the operation.  \n",
      "\n",
      "(Visuals deferred by unspecified time)\n",
      "Former Bangladeshi Prime Minister #SheikhHasina accused the #UnitedStates of influencing her resignation to gain control over Saint Martin Island and the Bay of Bengal\n",
      "\n",
      "Details herehttp://toi.in/pzhTXY\n",
      "\n",
      "#Bangladesh #BangladeshCrisis\n",
      "#Watch | Visuals from #WestBengal as Junior doctors at #Kolkata's RG Kar Medical College and Hospital protest over the sexual assault and murder of a woman post-graduate trainee (PGT) doctor at the hospital\n",
      "'Please do not message or call me': Phone, WhatsApp hacked, claims #NCP (SP) MP #SupriyaSule \n",
      "\n",
      "Know morehttp://toi.in/_mHB6a62 \n",
      "\n",
      "#Delhi\n",
      "Gender row Olympic boxing champion Imane Khelif files complaint for online harassment: Lawyer\n",
      "\n",
      "READ: http://toi.in/EoMCJZ/a24gk\n",
      "\n",
      "#ImaneKhelif #Paris2024 #OlympicGames\n",
      "#WATCH | Visuals from #Amritsar, #Punjab as Captain of the Indian men's #Hockey team #HarmanpreetSingh says, \"I am feeling very happy...We offered prayers at Sri Harmandir Sahib (Golden Temple)...\" \n",
      "\n",
      "#ParisOlympics2024 #Paris2024 #Olympics2024Paris\n",
      "Thousands hit streets in protest against attacks post-#Hasina exit in #Bangladesh\n",
      "#MadhabiPuriBuch, #SEBI chairperson, and her husband, #DhavalBuch, denied allegations by #HindenburgResearch regarding their involvement in offshore entities tied to the #AdaniGroup scandal\n",
      "\n",
      "Know morehttp://toi.in/PTlK8Z\n",
      "#Watch | Visuals from #Haryana's #Gurugram as severe waterlogging witnessed after incessant rainfall in the area; visuals from Gurugram Sector 5\n",
      "#Paris2024 #NeerajChopra\n",
      "\n",
      "If my throwing angle improves, I can throw better: Neeraj Chopra\n",
      "\n",
      "Read: http://toi.in/BSbQAb/a24gk\n",
      "A grieving sub-adult elephant stood near the carcass of his mother for hours with tears rolling down from his eyes, trying to wake her up.\n",
      "\n",
      "The calf returned to the forest only after realising his mother won't wake up.\n",
      "\n",
      "Details here  http://toi.in/oikG2Z \n",
      "\n",
      "#Odisha #Keonjhar\n",
      "Former Bangladeshi Prime Minister #SheikhHasina accused the #UnitedStates of influencing her resignation to gain control over Saint Martin Island and the Bay of Bengal\n",
      "\n",
      "Details herehttp://toi.in/pzhTXY\n",
      "\n",
      "#Bangladesh #BangladeshCrisis\n",
      "#Watch | Visuals from #WestBengal as Junior doctors at #Kolkata's RG Kar Medical College and Hospital protest over the sexual assault and murder of a woman post-graduate trainee (PGT) doctor at the hospital\n",
      "'Please do not message or call me': Phone, WhatsApp hacked, claims #NCP (SP) MP #SupriyaSule \n",
      "\n",
      "Know morehttp://toi.in/_mHB6a62 \n",
      "\n",
      "#Delhi\n",
      "Gender row Olympic boxing champion Imane Khelif files complaint for online harassment: Lawyer\n",
      "\n",
      "READ: http://toi.in/EoMCJZ/a24gk\n",
      "\n",
      "#ImaneKhelif #Paris2024 #OlympicGames\n",
      "#WATCH | Visuals from #Amritsar, #Punjab as Captain of the Indian men's #Hockey team #HarmanpreetSingh says, \"I am feeling very happy...We offered prayers at Sri Harmandir Sahib (Golden Temple)...\" \n",
      "\n",
      "#ParisOlympics2024 #Paris2024 #Olympics2024Paris\n",
      "Thousands hit streets in protest against attacks post-#Hasina exit in #Bangladesh\n",
      "#MadhabiPuriBuch, #SEBI chairperson, and her husband, #DhavalBuch, denied allegations by #HindenburgResearch regarding their involvement in offshore entities tied to the #AdaniGroup scandal\n",
      "\n",
      "Know morehttp://toi.in/PTlK8Z\n",
      "#Watch | Visuals from #Haryana's #Gurugram as severe waterlogging witnessed after incessant rainfall in the area; visuals from Gurugram Sector 5\n",
      "#Paris2024 #NeerajChopra\n",
      "\n",
      "If my throwing angle improves, I can throw better: Neeraj Chopra\n",
      "\n",
      "Read: http://toi.in/BSbQAb/a24gk\n",
      "A grieving sub-adult elephant stood near the carcass of his mother for hours with tears rolling down from his eyes, trying to wake her up.\n",
      "\n",
      "The calf returned to the forest only after realising his mother won't wake up.\n",
      "\n",
      "Details here  http://toi.in/oikG2Z \n",
      "\n",
      "#Odisha #Keonjhar\n",
      "Former Bangladeshi Prime Minister #SheikhHasina accused the #UnitedStates of influencing her resignation to gain control over Saint Martin Island and the Bay of Bengal\n",
      "\n",
      "Details herehttp://toi.in/pzhTXY\n",
      "\n",
      "#Bangladesh #BangladeshCrisis\n",
      "#Watch | Visuals from #WestBengal as Junior doctors at #Kolkata's RG Kar Medical College and Hospital protest over the sexual assault and murder of a woman post-graduate trainee (PGT) doctor at the hospital\n",
      "'Please do not message or call me': Phone, WhatsApp hacked, claims #NCP (SP) MP #SupriyaSule \n",
      "\n",
      "Know morehttp://toi.in/_mHB6a62 \n",
      "\n",
      "#Delhi\n",
      "Gender row Olympic boxing champion Imane Khelif files complaint for online harassment: Lawyer\n",
      "\n",
      "READ: http://toi.in/EoMCJZ/a24gk\n",
      "\n",
      "#ImaneKhelif #Paris2024 #OlympicGames\n",
      "#WATCH | Visuals from #Amritsar, #Punjab as Captain of the Indian men's #Hockey team #HarmanpreetSingh says, \"I am feeling very happy...We offered prayers at Sri Harmandir Sahib (Golden Temple)...\" \n",
      "\n",
      "#ParisOlympics2024 #Paris2024 #Olympics2024Paris\n",
      "Thousands hit streets in protest against attacks post-#Hasina exit in #Bangladesh\n",
      "#MadhabiPuriBuch, #SEBI chairperson, and her husband, #DhavalBuch, denied allegations by #HindenburgResearch regarding their involvement in offshore entities tied to the #AdaniGroup scandal\n",
      "\n",
      "Know morehttp://toi.in/PTlK8Z\n",
      "#Watch | Visuals from #Haryana's #Gurugram as severe waterlogging witnessed after incessant rainfall in the area; visuals from Gurugram Sector 5\n",
      "#Paris2024 #NeerajChopra\n",
      "\n",
      "If my throwing angle improves, I can throw better: Neeraj Chopra\n",
      "\n",
      "Read: http://toi.in/BSbQAb/a24gk\n",
      "A grieving sub-adult elephant stood near the carcass of his mother for hours with tears rolling down from his eyes, trying to wake her up.\n",
      "\n",
      "The calf returned to the forest only after realising his mother won't wake up.\n",
      "\n",
      "Details here  http://toi.in/oikG2Z \n",
      "\n",
      "#Odisha #Keonjhar\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/timesofindia')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list1 = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list1) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list1:  # Avoid duplicates\n",
    "                tweets_list1.append(tweet_text)\n",
    "            if len(tweets_list1) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(100)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list1\n",
    "\n",
    "def extract_tweets_parallel(driver, num_tweets, num_threads):\n",
    "    # Split the task into chunks for each thread\n",
    "    tweets_list1 = []\n",
    "    \n",
    "    def task():\n",
    "        nonlocal tweets_list1\n",
    "        new_tweets = extract_tweets_from_page(driver, num_tweets // num_threads)\n",
    "        tweets_list1.extend(new_tweets)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(task) for _ in range(num_threads)]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    return tweets_list1\n",
    "\n",
    "# Extract 50 tweets using 5 threads\n",
    "tweets_list1 = extract_tweets_parallel(driver, 50, 5)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list1:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29dfd466-ea4a-4d86-bd92-73c32cdfd95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 50\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bc3cd85-9413-467b-b6dc-0f6b29c3d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'timesofindia_tweets.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list1:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08ff98d1-5f42-4507-9d67-d9003bee8382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='timesofindia_tweets.csv' target='_blank'>timesofindia_tweets.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\timesofindia_tweets.csv"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Create a link to download the file\n",
    "file_link = FileLink('timesofindia_tweets.csv')\n",
    "file_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0261b2c-c6f0-408e-9894-f895ffe6a9be",
   "metadata": {},
   "source": [
    "6. thread pooling - the_hindu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8fb6e24a-f28f-43d9-aac0-8134f18ee072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n",
      "Tripura's connectivity project with #Bangladesh - the Agartala-Akhaura rail link and Maitree bridge - may be delayed due to the political turmoil and change in government in the neighbouring country, state Transport minister Sushanta Chowdhury said.\n",
      "President #DroupadiMurmu on Sunday left for home after concluding her three-nation visit to Fiji, New Zealand and Timor-Leste aimed at giving impetus to India’s ties with them.\n",
      "#LisaFrankenstein review: #KathrynNewton and #ColeSprouse's teen/ horror/ monster/ slasher/ period film would have been served better if it could make up its mind about its identity\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/the_hindu')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list2 = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list2) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list2:  # Avoid duplicates\n",
    "                tweets_list2.append(tweet_text)\n",
    "            if len(tweets_list2) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list2\n",
    "\n",
    "def extract_tweets_parallel(driver, num_tweets, num_threads):\n",
    "    # Split the task into chunks for each thread\n",
    "    tweets_list2 = []\n",
    "    \n",
    "    def task():\n",
    "        nonlocal tweets_list2\n",
    "        new_tweets = extract_tweets_from_page(driver, num_tweets // num_threads)\n",
    "        tweets_list2.extend(new_tweets)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(task) for _ in range(num_threads)]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    return tweets_list2\n",
    "\n",
    "# Extract 100 tweets using 5 threads\n",
    "tweets_list2 = extract_tweets_parallel(driver, 50, 15)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list2:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c348dfe-26b9-4c6e-80db-98578b94e6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 45\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fb337c7c-e4f0-48f9-a54e-25f0d0b15f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'the_hindu.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list2:\n",
    "        writer.writerow([tweet])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "485cee96-60b3-49d0-b2ab-465d592714dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='the_hindu.csv' target='_blank'>the_hindu.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\the_hindu.csv"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Create a link to download the file\n",
    "file_link = FileLink('the_hindu.csv')\n",
    "file_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eccb88b-84cb-45c6-a1b1-9bb48a14f26d",
   "metadata": {},
   "source": [
    "hindustan times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b79ab674-87f4-4abf-89db-1cb287b09c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n",
      "#Paris2024 | India ends campaign in Paris Olympics with six medals including one silver and five bronze \n",
      "\n",
      "Follow our coverage on https://hindustantimes.com/sports/olympics\n",
      "#WATCH | Severe waterlogging witnessed in parts of #Noida after incessant #rainfall. \n",
      "\n",
      "Track all the latest updates here: https://hindustantimes.com\n",
      "\n",
      "( ANI )\n",
      "#HTNewsBrief | Here's a look at everything that's making news at this hour\n",
      "\n",
      "https://hindustantimes.com/india-news/evening-briefing-bjp-claims-cover-up-in-kolkata-doctors-murder-maldivian-oppn-backs-muizzus-india-policy-shift-more-101723372476929.html…\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/htTweets')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list3 = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list3) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list3:  # Avoid duplicates\n",
    "                tweets_list3.append(tweet_text)\n",
    "            if len(tweets_list3) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list3\n",
    "\n",
    "def extract_tweets_parallel(driver, num_tweets, num_threads):\n",
    "    # Split the task into chunks for each thread\n",
    "    tweets_list3 = []\n",
    "    \n",
    "    def task():\n",
    "        nonlocal tweets_list3\n",
    "        new_tweets = extract_tweets_from_page(driver, num_tweets // num_threads)\n",
    "        tweets_list3.extend(new_tweets)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(task) for _ in range(num_threads)]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    return tweets_list3\n",
    "\n",
    "# Extract 50 tweets using 5 threads\n",
    "tweets_list3 = extract_tweets_parallel(driver, 50, 15)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list3:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a0560364-2fbe-4a45-9ac0-b2b1232d2fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 45\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "25701e73-a466-429b-ad84-d9c15eb1ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'hindustan_times.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list3:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "139273f2-e65b-423b-a1d8-7e5c7c181f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='hindustan_times.csv' target='_blank'>hindustan_times.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\hindustan_times.csv"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "# Create a link to download the file\n",
    "file_link1 = FileLink('hindustan_times.csv')\n",
    "file_link1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27294f-3f80-4e2b-8b0d-fdb1660148fd",
   "metadata": {},
   "source": [
    "env- natgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a0dcf956-8846-4110-9627-596384751c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How the nation chooses its best and brightest Christmas trees \n",
      "Indian star tortoises are in jeopardy as good luck charms. Here's what we know \n",
      "How the nation chooses its best and brightest Christmas trees \n",
      "Indian star tortoises are in jeopardy as good luck charms. Here's what we know \n",
      "How the nation chooses its best and brightest Christmas trees \n",
      "Indian star tortoises are in jeopardy as good luck charms. Here's what we know \n",
      "How the nation chooses its best and brightest Christmas trees \n",
      "Indian star tortoises are in jeopardy as good luck charms. Here's what we know \n",
      "How the nation chooses its best and brightest Christmas trees \n",
      "Indian star tortoises are in jeopardy as good luck charms. Here's what we know \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/NatGeo')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list4 = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list4) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list4:  # Avoid duplicates\n",
    "                tweets_list4.append(tweet_text)\n",
    "            if len(tweets_list4) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list4\n",
    "\n",
    "def extract_tweets_parallel(driver, num_tweets, num_threads):\n",
    "    # Split the task into chunks for each thread\n",
    "    tweets_list4 = []\n",
    "    \n",
    "    def task():\n",
    "        nonlocal tweets_list4\n",
    "        new_tweets = extract_tweets_from_page(driver, num_tweets // num_threads)\n",
    "        tweets_list4.extend(new_tweets)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(task) for _ in range(num_threads)]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    return tweets_list4\n",
    "\n",
    "# Extract 50 tweets using 5 threads\n",
    "tweets_list4 = extract_tweets_parallel(driver, 10, 5)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list4:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4211a6c0-116b-4fe3-8209-0504b96844b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7606c799-eed4-45d7-a3cf-68ac0c218904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'env_nat_geo.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list4:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "06f1b7fe-6b80-46f9-b446-6cb7d0efa69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='env_nat_geo.csv' target='_blank'>env_nat_geo.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\env_nat_geo.csv"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "# Create a link to download the file\n",
    "file_link1 = FileLink('env_nat_geo.csv')\n",
    "file_link1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b9452-d6c3-4a61-a265-96e9b64d3ba0",
   "metadata": {},
   "source": [
    "economy= theeconomist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "02ce1772-f6ca-47ab-8bb4-84a81f038975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n",
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      " Our Big Mac index reveals whether a currency is undervalued or overvalued against the dollar https://econ.st/4dFab6x \n",
      "The impact of legal doping would be unlikely to revolutionise sport in the way that proponents claim. But the normalisation of drug-taking would entail serious health risks https://econ.st/4fsOIPT \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/TheEconomist')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list5 = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list5) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list5:  # Avoid duplicates\n",
    "                tweets_list5.append(tweet_text)\n",
    "            if len(tweets_list5) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list5\n",
    "\n",
    "def extract_tweets_parallel(driver, num_tweets, num_threads):\n",
    "    # Split the task into chunks for each thread\n",
    "    tweets_list5 = []\n",
    "    \n",
    "    def task():\n",
    "        nonlocal tweets_list5\n",
    "        new_tweets = extract_tweets_from_page(driver, num_tweets // num_threads)\n",
    "        tweets_list5.extend(new_tweets)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(task) for _ in range(num_threads)]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    return tweets_list5\n",
    "\n",
    "# Extract 50 tweets using 5 threads\n",
    "tweets_list5 = extract_tweets_parallel(driver, 50, 15)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list5:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "01380009-2877-4b57-b0c4-9436ef83eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 45\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4841e75d-7ae4-4710-9a0e-8668f3d8a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'economy.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list5:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "34eefdd4-bc40-4f27-a4f1-f37b7fa3f0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='economy.csv' target='_blank'>economy.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\economy.csv"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "# Create a link to download the file\n",
    "file_link1 = FileLink('economy.csv')\n",
    "file_link1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9194618-80a9-4887-bd55-0a5dba725dc4",
   "metadata": {},
   "source": [
    "sport- BBCSport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6a141e80-511d-44f4-8241-6e363546e54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n",
      "It's the final day at #Paris2024 \n",
      "\n",
      "Here's some of the action we'll bring you across \n",
      "@BBCOne\n",
      " and \n",
      "@BBCiPlayer\n",
      " \n",
      "\n",
      "#Paris2024 #Olympics #BBCOlympics\n",
      "They've both had an incredible games! \n",
      "\n",
      "#BBCOlympics #Olympics #Paris2024\n",
      "\"The Olympics is the best of the best.\" \n",
      "\n",
      "US basketball star \n",
      "@breannastewart\n",
      " has a collection of titles and accolades to her name, but there's nothing quite like the Olympic feeling.\n",
      "\n",
      "Can she win a third  with \n",
      "@TeamUSA\n",
      "? \n",
      "\n",
      "Listen to #OnThePodium  https://bbc.co.uk/sounds/play/w3ct5hzn…\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/BBCSport')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list6 = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list6) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list6:  # Avoid duplicates\n",
    "                tweets_list6.append(tweet_text)\n",
    "            if len(tweets_list6) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list6\n",
    "\n",
    "def extract_tweets_parallel(driver, num_tweets, num_threads):\n",
    "    # Split the task into chunks for each thread\n",
    "    tweets_list6 = []\n",
    "    \n",
    "    def task():\n",
    "        nonlocal tweets_list6\n",
    "        new_tweets = extract_tweets_from_page(driver, num_tweets // num_threads)\n",
    "        tweets_list6.extend(new_tweets)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(task) for _ in range(num_threads)]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    return tweets_list6\n",
    "\n",
    "# Extract 50 tweets using 5 threads\n",
    "tweets_list6 = extract_tweets_parallel(driver, 50, 15)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list6:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "25689590-0d0c-4767-9074-bc854149343d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 45\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "df5b419e-0c8d-4795-ab52-74ad98a1b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'sports.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list6:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4dcc49ef-e644-41d5-8f08-d3390e6c2468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sports.csv' target='_blank'>sports.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\sports.csv"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "# Create a link to download the file\n",
    "file_link1 = FileLink('sports.csv')\n",
    "file_link1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b122fb-5112-4970-a578-9bcbd7df2a30",
   "metadata": {},
   "source": [
    "politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9a5ebc55-9cc5-418b-8aa1-54d09e66d077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(3)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(3)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(3)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/BBCPolitics')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list7 = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list7) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list7:  # Avoid duplicates\n",
    "                tweets_list7.append(tweet_text)\n",
    "            if len(tweets_list7) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list7\n",
    "\n",
    "def extract_tweets_parallel(driver, num_tweets, num_threads):\n",
    "    # Split the task into chunks for each thread\n",
    "    tweets_list7 = []\n",
    "    \n",
    "    def task():\n",
    "        nonlocal tweets_list7\n",
    "        new_tweets = extract_tweets_from_page(driver, num_tweets // num_threads)\n",
    "        tweets_list7.extend(new_tweets)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(task) for _ in range(num_threads)]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()  # Wait for all threads to complete\n",
    "\n",
    "    return tweets_list7\n",
    "\n",
    "# Extract 50 tweets using 5 threads\n",
    "tweets_list7 = extract_tweets_parallel(driver, 30, 15)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list7:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "185aab27-705a-4887-bdd2-b0421356cd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list7)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "900942cc-dc61-416f-970f-15ca5a3cf06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'politics.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list7:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7d99228f-2fb1-4edf-ab28-95cf4423d161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='politics.csv' target='_blank'>politics.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\politics.csv"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "# Create a link to download the file\n",
    "file_link1 = FileLink('politics.csv')\n",
    "file_link1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d3bd5-3b7d-4405-bee0-7e63b50a36f4",
   "metadata": {},
   "source": [
    "try to fetch more tweets --> try and error method as im getting duplicate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a12cff07-b879-4e04-bcd5-47ff4010b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America’s economy is not entering recession, but it is slowing down. That is bad news for Kamala Harris https://econ.st/3T4hyfZ\n",
      "This week on “Drum Tower” \n",
      "@donweinland\n",
      " and Rosie Blau explore the rise and fall of Western fast food in China. What’s behind the change in the country’s tastes? https://econ.st/4caT776 \n",
      "Republicans and Democrats do not agree on much, but both parties want to help America’s “left­-behind”.\n",
      "\n",
      "Happily the economic fortunes of the country’s poorest have massively improved in recent years. But manufacturing jobs are still in decline https://econ.st/46Efhxk \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/TheEconomist')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list:  # Avoid duplicates\n",
    "                tweets_list.append(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list\n",
    "\n",
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets_from_page(driver, 50)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)\n",
    "\n",
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'theeconomist_tweets.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list:\n",
    "        writer.writerow([tweet])\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cadc267a-25b4-4e05-b370-832ab7a3e5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "acfa3a04-43a7-47b2-8cc5-65fcf96b9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starmer will be judged on how he tackles root causes of riots\n",
      "On tonight’s Any Questions, \n",
      "@AlexForsythBBC\n",
      " is joined in Falmouth by Sir Robert Buckland, Inaya Folarin Iman, Dan Norris MP and Vicky Spratt.  #BBCAQ\n",
      "Listen 8pm Friday / 1.10pm Saturday on \n",
      "@BBCRadio4\n",
      " or on demand on \n",
      "@BBCSounds\n",
      ".\n",
      "https://bbc.in/3AiX4cM\n",
      "\"We absolutely have to make sure that our communities are safe and secure\"\n",
      " \n",
      "PM Keir Starmer reiterates his message to police to \"stay on high alert\" this weekend \n",
      " \n",
      "Follow live https://bbc.in/4cmnd7A\n",
      "Suspended Labour councillor Ricky Jones charged with encouraging violent disorder at London counter-protest\n",
      " \n",
      "Follow live:\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/BBCPolitics')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list:  # Avoid duplicates\n",
    "                tweets_list.append(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list\n",
    "\n",
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets_from_page(driver, 50)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)\n",
    "\n",
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'bbc_politics_tweets.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list:\n",
    "        writer.writerow([tweet])\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "92978226-e65e-418a-af93-7c57b10f017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a1439-6248-4dbc-9d34-62df95c43d80",
   "metadata": {},
   "source": [
    "extract data for prajakta --> american news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968df9f3-d046-4ad8-9e15-663d996802c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team USA women's basketball squad holds off France for its eighth straight Olympic gold\n",
      "US Olympic officials plan to appeal a court ruling that led to US gymnast Jordan Chiles being stripped of her bronze medal\n",
      "US gymnast Jordan Chiles will be stripped of a bronze medal after the International Olympic Committee reallocated it to Romanian gymnast Ana Bărbosu\n",
      "US men's basketball defeats host nation France, taking gold for the fifth consecutive Olympic Games. https://cnn.it/3LXWVhv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/CNN')\n",
    "time.sleep(10)  # Adjust as needed\n",
    "\n",
    "def extract_tweets_from_page(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text\n",
    "            if tweet_text and tweet_text not in tweets_list:  # Avoid duplicates\n",
    "                tweets_list.append(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Adjust as needed to allow tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list\n",
    "\n",
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets_from_page(driver, 50)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)\n",
    "\n",
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'bbc_politics_tweets.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list:\n",
    "        writer.writerow([tweet])\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682739ba-fe7c-4212-8807-c45e145c76d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e774c330-f6b1-4cd5-83e4-465e63d8989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team USA women's basketball squad holds off France for its eighth straight Olympic gold\n",
      "US Olympic officials plan to appeal a court ruling that led to US gymnast Jordan Chiles being stripped of her bronze medal\n",
      "US gymnast Jordan Chiles will be stripped of a bronze medal after the International Olympic Committee reallocated it to Romanian gymnast Ana Bărbosu\n",
      "US men's basketball defeats host nation France, taking gold for the fifth consecutive Olympic Games. https://cnn.it/3LXWVhv\n",
      "An 18-year-old Iraqi national was detained in Vienna over an alleged plot to attack a Taylor Swift concert in the Austrian capital, officials said\n",
      "Dramatic new bodycam video obtained by CNN shows, for the first time, the moment a police officer saw Trump shooter just before assassination attempt\n",
      "Team USA battles its way back after trailing Serbia by 17 points to make men's basketball final against Olympic host France\n",
      "Dow closes nearly 700 points higher after latest jobless data brings better news for America's labor market\n",
      "After his stunning defeat in 200-meter race at the Olympics today, USA sprinter Noah Lyles confirms he tested positive for Covid-19 earlier this week\n",
      "Trump and Harris are set to debate on ABC on September 10. Other potential faceoffs are still up in the air.\n",
      "Letsile Tebogo of Botswana stuns American Noah Lyles, previously crowned world's fastest man, to win the 200-meter race. Follow live Olympics updates. https://cnn.it/3SG35Xc\n",
      "US mortgage rates drop to their lowest level in more than a year -- a positive step in solving America's housing affordability crisis.\n",
      "Tropical Storm Debby makes landfall again, this time in South Carolina, after killing 5 and flooding parts of the Southeast\n",
      "Simone Biles, the 11-time Olympic medalist, opens up with CNN about how therapy helped her achieve a historic comeback in Paris after suffering from the \"twisties\" in Tokyo\n",
      "Yahya Sinwar, alleged \"mastermind\" of the October 7 terror attacks, will become head of Hamas' political bureau after his predecessor was assassinated.\n",
      "A Pakistani national with ties to Iran is charged in connection to a foiled assassination plot potentially targeting Trump and other US officials\n",
      "A former Kansas police chief will be charged over the 2023 raid on a small newspaper that drew condemnation from press freedom advocates, prosecutors say\n",
      "Kamala Harris picks Minnesota Gov. Tim Walz as her running mate, multiple sources say. He has been a leading driver of Democrats' attacks on Trump https://cnn.it/3YFCZqW\n",
      "Several US personnel were injured in a suspected rocket attack against US and coalition forces in Iraq, a US defense official says.\n",
      "Dow and S&P 500 finish their worst day since 2022 as investors fear the US economy is on shaky legs\n",
      "Supreme Court rejects Missouri lawsuit to block Trump's sentencing and gag order in New York hush money case\n",
      "Google has violated US antitrust law with its search business, federal judge rules, handing the tech giant a staggering court defeat\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/CNN')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "def extract_tweets(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    seen_tweets = set()  # To track unique tweets\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text.strip()  # Remove leading/trailing whitespace\n",
    "            if tweet_text and tweet_text not in seen_tweets:\n",
    "                tweets_list.append(tweet_text)\n",
    "                seen_tweets.add(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Allow time for new tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list\n",
    "\n",
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets(driver, 40)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e41201aa-65df-41ed-bfa5-31b0b5582053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 22\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdf139aa-fa98-464a-8483-2e6d1aa82424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'CNNnews.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32aabc9b-6416-42ea-bb04-4a5be555fb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='CNNnews.csv' target='_blank'>CNNnews.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\project main files\\CNNnews.csv"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "# Create a link to download the file\n",
    "file_link1 = FileLink('CNNnews.csv')\n",
    "file_link1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5abbf737-be35-4d22-b1bf-fd2aaa3c9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TikToker raises $360K+ to help disabled 90-year-old veteran struggling to pay rent\n",
      "Trump claims 'nobody' cheered Harris outside Air Force Two despite video, images of crowds\n",
      "BUBBLE POPPED: An iconic gumball demonstration seen by millions over the years is back in the spotlight as Kamala Harris faces growing scrutiny over her handling of the border crisis. How the pieces connect. https://trib.al/WZ0jmI6\n",
      "Former leader of Walz's battalion publishes scathing message aimed at governor's military career: Report\n",
      "Washington Post pushes Harris to answer 'legitimate questions' about her flip-flops, agenda\n",
      "Kamala Harris ripped for pivoting on border security: 'Outrageous'\n",
      "Jordan Chiles Paris Olympics bronze medal controversy is 'completely devastating,' US gymnastics great says\n",
      "Trump-Musk interview upsets Hollywood elites\n",
      "ADT hacked: Is your home security system really secure?\n",
      "BAD WITH MONEY: Kamala Harris' running mate is facing increased scrutiny after 'at least a quarter billion dollars' was stolen from a federally funded Minnesota program pushed by the governor. More details. https://trib.al/Y0aMaae\n",
      "Trump to sue DOJ for $100M over Mar-a-Lago raid, alleging 'political persecution'\n",
      "Vance hits Walz over military record\n",
      "Biden has another light schedule this week with 5 months until term ends\n",
      "Concha slams Harris for evading media since becoming Dem nominee: 'Zero ability to speak extemporaneously'\n",
      "Iran could attack Israel in less than 24 hours, sources say, as Western powers issue Tehran a warning\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/FoxNews')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "def extract_tweets(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    seen_tweets = set()  # To track unique tweets\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text.strip()  # Remove leading/trailing whitespace\n",
    "            if tweet_text and tweet_text not in seen_tweets:\n",
    "                tweets_list.append(tweet_text)\n",
    "                seen_tweets.add(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)  # Allow time for new tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list\n",
    "\n",
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets(driver, 20)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b3fe418-86f6-4d33-b241-47a24959ab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8860fd21-74b3-434d-9578-ca8695a0076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'foxnews.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e60d77e5-651a-47b9-bce3-8d4e15ee924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='foxnews.csv' target='_blank'>foxnews.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\project main files\\foxnews.csv"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "# Create a link to download the file\n",
    "file_link1 = FileLink('foxnews.csv')\n",
    "file_link1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd05ca-d8a6-4a0f-9b78-104c425c6249",
   "metadata": {},
   "source": [
    "ACB news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88ee8934-1135-4843-9188-63dc8afa4f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Street artist Banksy has unveiled a new mural of a rhinoceros that looks like it is climbing on top of a car in London.\n",
      "While the weekend passed with no direct retaliation from Hezbollah for the killings of several top leaders by Israeli strikes, the group said it still plans to strike.\n",
      "A British man, who was seen climbing the Eiffel Tower on the last day of the Paris Olympics, has been released from police custody, but remains under investigation for trespassing at a historical site, French prosecutors said Monday.\n",
      "NEW: Former Pres. Donald Trump, in a post to his conservative social media site Truth Social, announced he will be interviewed live by Elon Musk on X at 8 p.m. ET.\n",
      "Sweden has dropped its investigation into a backstage altercation in May involving the Dutch contestant in the Eurovision Song Contest who was expelled from the competition hours before the final.\n",
      "The woman who says she helped save Graceland from possible foreclosure is sharing her side of the saga for the first time. https://trib.al/YcfiaI8\n",
      "Jury selection is set to begin Monday in the trial of Susan Lorincz, the Florida woman who is charged with fatally shooting her neighbor Ajike \"AJ\" Owens, a Black mother of four, in 2023 amid a dispute with Owens' children.\n",
      "Susan Wojcicki, a pioneering tech executive who helped shape Google and YouTube, has died, her husband said. She was 56. https://trib.al/qX3nsxP\n",
      "Colleges large and small in the U.S. are cutting programs and eliminating majors to make ends meet.\n",
      "Costco Wholesale will add membership scanners to combat customers who have shared their card to let friends shop.\n",
      "Kate Middleton, the Princess of Wales, has appeared alongside a host of other celebrities congratulating Team GB on their olympic success as the 2024 Games comes to a close in Paris. https://trib.al/0VtdpOk\n",
      "An allegedly stolen identity and a possible foreclosure — the woman who says she helped save Graceland is sharing her side of the saga for the first time.\n",
      "https://trib.al/wCBlv10\n",
      "A makeshift aquarium established by two longtime Brooklyn residents in a sidewalk tree pit often flooded by a leaky fire hydrant has stirred controversy.\n",
      "Skywatchers and beachgoers reported several waterspouts on Lake Erie on Sunday morning. \n",
      "\n",
      "A special marine warning for wind, hail and waterspouts were in place for the area near Mentor, Ohio, during the time they were spotted.\n",
      "The 35th season of Homer, Marge, Bart, Lisa and Maggie is heading to Disney+ on Oct. 2 with some brand-new surprises.\n",
      "A woman died Thursday at Chicago O'Hare International Airport after getting caught in a baggage carousel, officials told \n",
      "@ABC\n",
      " News.\n",
      "An \"Avatar\" experience and a \"Coco\" ride are coming to Disney California Adventure Park, Disney Experiences Chairman Josh D'Amaro announced at the D23 fan event.\n",
      "With climate change fueling more damaging and deadly weather events, experts question if the effects of global warming have fallen victim to over-politicization on the national stage.\n",
      "Small businesses along popular vacation destinations like boardwalks and piers in the U.S. say the number of tourists flocking to the waterfront is back to normal, meaning pre-2020 levels.\n",
      "Tom Cruise closed out the 2024 Paris Olympics \"Mission Impossible\" style — by rappelling down from the roof of Stade de France.\n",
      "\n",
      "Read more: https://trib.al/xGmN3ug\n",
      "Israeli forces intercept 'projectiles' crossing from Lebanon. No injuries have been reported, IDF says.\n",
      "JUST IN: Two people have been found dead and another was injured after an explosion Sunday in a suburban Baltimore neighborhood, authorities say.\n",
      "A new Instagram filter will allow Jackson Hole visitors to interact with nature while keeping a safe distance from wildlife.\n",
      "The 2024 MTV Video Music Award nominations are here, and Taylor Swift leads this year's nominations with 10 nods.\n",
      "\n",
      "See the full list of nominees:\n",
      "Robin Williams' son, Zachary Pym Williams, paid tribute to his father on Instagram on Sunday, 10 years to the day after Williams died.\n",
      "Tom Cruise closed out the 2024 Paris Olympics by rappelling down from the roof of Stade de France.\n",
      "In the Ryan Reynolds-Blake Lively box-office showdown, both husband and wife came out winners.\n",
      "Before Vice Pres. Kamala Harris decided Minnesota Gov. Tim Walz would be her running mate, she had a talented field of finalists.\n",
      "\n",
      "Here's a look at the two men who came closest to being picked:\n",
      "Ocean temperatures in the Great Barrier Reef hit their highest level in 400 years over the past decade, according to researchers who warned that the reef likely won’t survive if planetary warming isn’t stopped.\n",
      "A new study suggests a popular artificial sweetener could be linked to a higher risk of blood clots, but the researchers themselves say their findings are preliminary and more research is needed to understand any potential health risks.\n",
      "A suspected serial killer already in custody in North Carolina for a cold case murder has been charged in the slayings of three women who were strangled to death in 1977 in California, authorities said.\n",
      "The U.S. Navy is struggling to build affordable warships needed to face expanding threats around the world.\n",
      "LATEST: The Israel Defense Forces on Sunday ordered civilians in the al-Jalaa neighborhood of northern Khan Younis to evacuate as Israeli troops began raiding the area it alleges is being used by Hamas terrorists.\n",
      "Minnesota Sen. Amy Klobuchar, D, Democrats are \"moving forward\" after President Biden ended his reelection campaign and passed the baton to Vice President Harris.\n",
      "LATEST: Several people suffered \"minor injuries\" after a U.S. military base in eastern Syria was attacked by a one-way drone, officials said Sunday, including smoke inhalation, while others were examined for traumatic brain injuries.\n",
      "When an American traveler was able to get a travel voucher from an airline to stay in Italy a bit longer, she had no idea it would essentially lead to getting paid to travel.\n",
      "A Federal Bureau of Prisons employee died after coming into contact with an unknown substance in the mailroom at the U.S. penitentiary in Atwater, California, according to a bureau spokesperson. https://trib.al/e4zYJ3S\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/ABC')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "def extract_tweets(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    seen_tweets = set()  # To track unique tweets\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text.strip()  # Remove leading/trailing whitespace\n",
    "            if tweet_text and tweet_text not in seen_tweets:\n",
    "                tweets_list.append(tweet_text)\n",
    "                seen_tweets.add(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(15)  # Allow time for new tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list\n",
    "\n",
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets(driver, 40)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aa70848-9d46-4945-a8ed-60e59558bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 37\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "265285ce-cfac-421f-9960-d4f59ac40e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'ABCnews.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4aa4ac2-ffc2-445e-b87f-ba1c4bc58402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='ABCnews.csv' target='_blank'>ABCnews.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\project main files\\ABCnews.csv"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "# Create a link to download the file\n",
    "file_link1 = FileLink('ABCnews.csv')\n",
    "file_link1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62907b92-8539-4260-8af3-cdd3453e6f61",
   "metadata": {},
   "source": [
    "nytimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e2a44c6-8b2f-4622-a10d-f7dc66e06bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a guide to how you can keep up with The New York Times, on and off Twitter.\n",
      "@nytimes\n",
      " shares news to help you understand the world.\n",
      "@nytopinion\n",
      " offers crucial perspectives on the issues that matter to you.\n",
      "A gas explosion in northern Maryland destroyed a house on Sunday morning, killing the homeowner and contractor who had been despatched to investigate a purported leak in the home, fire officials said.\n",
      "An Alabama Supreme Court ruling in February that deemed frozen embryos were “unborn children” has motivated some patients and clinics to move embryos out of red states.\n",
      "The leaders of Britain, France and Germany urged Iran to avoid inflaming regional tensions, warning in a joint statement that a military escalation in the Middle East could disrupt efforts to reach a cease-fire in Gaza. Follow for more updates.\n",
      "Breaking News: Two people, including an 11-year-old girl, were stabbed in London’s Leicester Square, the police said. A man has been arrested.\n",
      "Close allies of Donald Trump say he has made a string of damaging mistakes, disoriented by Kamala Harris entering the presidential race and unsure of how to take her on.\n",
      "From \n",
      "@TheAthletic\n",
      ": These were the first Olympics that sought full gender parity — with as many women athletes competing as men. And their athletic brilliance was on display right from the jump, culminating in a gritty U.S. women's basketball gold.\n",
      "Russian forces are pummeling Ukrainian positions along the front lines, even as Ukraine's incursion onto Russian soil continues, Ukrainian military officials said on Monday. “Our guys do not feel any relief.\"\n",
      "Connections is a daily game about finding common threads between words. Players must select four groups of four words without making more than three mistakes. Play now. https://nyti.ms/3AmAoIF\n",
      "A 22-year-old man was charged with assault as a hate crime after the police said he yelled “Free Palestine” and “Do you want to die?” before stabbing a young Jewish man in the chest near a synagogue in Brooklyn on Saturday.\n",
      "Donald Trump is struggling to adjust to his new opponent in the 2024 race, Kamala Harris. Listen to \"The Daily\" for an inside look at the three worst weeks of Trump's campaign.\n",
      "Even after restoring order to Britain in the wake of two weeks of anti-immigrant riots, Prime Minister Keir Starmer faces a bigger challenge: defusing the issues of fraying public services and a cost of living crisis that underlie the unrest.\n",
      "After spending three weeks in one of Gaza’s last functioning hospitals, Dr. Ahmad Yousaf, an American pediatrician, described the severe toll of the war on medical workers and civilians, particularly children. https://nyti.ms/4difs3P\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "username = os.getenv('TWITTER_USERNAME')\n",
    "password = os.getenv('TWITTER_PASSWORD')\n",
    "\n",
    "# Set up WebDriver\n",
    "service = Service(executable_path='C:\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Log in to Twitter\n",
    "username_field = driver.find_element(By.NAME, 'text')\n",
    "username_field.send_keys(username)\n",
    "username_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "password_field = driver.find_element(By.NAME, 'password')\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "# Navigate to a user's timeline\n",
    "driver.get('https://twitter.com/nytimes')\n",
    "time.sleep(5)  # Adjust as needed\n",
    "\n",
    "def extract_tweets(driver, num_tweets):\n",
    "    tweets_list = []\n",
    "    seen_tweets = set()  # To track unique tweets\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while len(tweets_list) < num_tweets:\n",
    "        # Extract tweets\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]//div[@lang]')\n",
    "        for tweet in tweets:\n",
    "            tweet_text = tweet.text.strip()  # Remove leading/trailing whitespace\n",
    "            if tweet_text and tweet_text not in seen_tweets:\n",
    "                tweets_list.append(tweet_text)\n",
    "                seen_tweets.add(tweet_text)\n",
    "            if len(tweets_list) >= num_tweets:\n",
    "                break\n",
    "\n",
    "        # Scroll down the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(15)  # Allow time for new tweets to load\n",
    "\n",
    "        # Check if we have reached the bottom of the page\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If no more tweets are loading, break out of the loop\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets_list\n",
    "\n",
    "# Extract 50 tweets\n",
    "tweets_list = extract_tweets(driver, 40)\n",
    "\n",
    "# Print the extracted tweets\n",
    "for tweet in tweets_list:\n",
    "    print(tweet)\n",
    "\n",
    "# # Optionally, save tweets to a CSV file\n",
    "# csv_file = 'timesofindia_tweets.csv'\n",
    "# with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Tweet'])  # Header\n",
    "#     for tweet in tweets_list:\n",
    "#         writer.writerow([tweet])\n",
    "\n",
    "# # Close the driver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21229ce4-c556-4805-bd32-cfc87787a624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets found: 13\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets found: {len(tweets_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bc42a14-38a5-4c10-8382-68414fc2a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save tweets to a CSV file\n",
    "csv_file = 'nytimesnews.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Tweet'])  # Header\n",
    "    for tweet in tweets_list:\n",
    "        writer.writerow([tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79c82d89-2f96-423b-9c29-9021100d0701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='nytimesnews.csv' target='_blank'>nytimesnews.csv</a><br>"
      ],
      "text/plain": [
       "G:\\modules\\module -9 (Project)\\TWITTER\\project main files\\nytimesnews.csv"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "# Create a link to download the file\n",
    "file_link1 = FileLink('nytimesnews.csv')\n",
    "file_link1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
